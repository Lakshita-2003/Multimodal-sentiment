ğŸ§  Multimodal Sentiment Analysis using Deep Learning

A research-oriented project for sentiment classification using text, audio, and video modalities â€” featuring ResNet-18, EfficientNet-B0, ConvNeXt-Tiny, ViT-B/16, and a custom Hybrid Fusion Transformer (ViT + AST) model.

The system performs feature extraction, fusion, training, and benchmarking across multiple architectures on GPU.


ğŸš€ Features

ğŸ—‚ Automatic dataset generation for text, audio, and video
ğŸ§© Pretrained embedding extraction (DistilBERT, Wav2Vec2, ViT-Base)

ğŸ¤– Multiple deep learning models
ResNet-18
EfficientNet-B0
ConvNeXt-Tiny
ViT-B/16
Hybrid Fusion Transformer (ours)

ğŸ“Š Benchmark pipeline â€“ trains, evaluates, and compares all models automatically
âš¡ GPU acceleration (CUDA supported)
ğŸ“ˆ Generates professional-style comparison graphs for accuracy & F1-scores


ğŸ— Project Structure

multimodal-sentiment/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_creation/            # Synthetic or manifest-based dataset generators
â”‚   â”œâ”€â”€ feature_extraction/       # Pretrained embedding extractors
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ cnn_variants/         # ResNet, EfficientNet, ConvNeXt training scripts
â”‚   â”‚   â”œâ”€â”€ transformer_variants/ # ViT-B16 training script
â”‚   â”‚   â”œâ”€â”€ fusion_variants/      # Hybrid fusion model
â”‚   â”‚   â”œâ”€â”€ compare_all_models.py # Performance comparison chart
â”‚   â”‚   â”œâ”€â”€ evaluate_model.py     # Unified evaluation script
â”‚   â”‚   â”œâ”€â”€ train_all_models.py   # Benchmark automation
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ train.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ manifest_train.csv
â”‚   â”œâ”€â”€ features/                 # Extracted pretrained embeddings (text/audio/video)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/                      # Trained weights, logs, charts
â”‚   â”œâ”€â”€ resnet18_best.pt
â”‚   â”œâ”€â”€ efficientnet_b0_best.pt
â”‚   â”œâ”€â”€ convnext_tiny_best.pt
â”‚   â”œâ”€â”€ vit_b16_best.pt
â”‚   â”œâ”€â”€ hybrid_fusion_best.pt
â”‚   â”œâ”€â”€ comparison_chart.png
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md



âš™ï¸ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/Lakshita-2003/multimodal-sentiment.git
cd multimodal-sentiment

2ï¸âƒ£ Create and activate a virtual environment
python -m venv venv
venv\Scripts\activate     # On Windows
# source venv/bin/activate  # On Mac/Linux

3ï¸âƒ£ Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

4ï¸âƒ£ (Optional) Install CUDA support

Ensure your PyTorch installation matches your GPU CUDA version:
ğŸ‘‰ https://pytorch.org/get-started/locally/



ğŸ§¾ Dataset Preparation

The dataset can be generated or expanded automatically: python src/data_creation/generate_large_dataset.py

This will:
Create synthetic text, audio, and video samples
Generate manifest files (manifest_train.csv, manifest_val.csv, manifest_test.csv)
Store all paths under data/



ğŸ§ Pretrained Feature Extraction

Run to extract DistilBERT, Wav2Vec2, and ViT features for each modality: python src/feature_extraction/pretrained/extract_pretrained_embeddings.py


Embeddings will be stored under:

data/features/text/
data/features/audio/
data/features/video/



ğŸ§  Training and Evaluation
â–¶ï¸ Train all models (automated benchmark): python -m src.models.train_all_models

This will:
Train all CNNs + ViT + HybridFusion
Evaluate each model
Save checkpoints and logs under results/

â–¶ï¸ Evaluate a specific model: python -m src.models.evaluate_model



ğŸ“ˆ Comparison Graph
After all models are trained:
python -m src.models.compare_all_models


This generates: results/comparison_chart.png
â†’ Accuracy + F1 for all models (publication-ready)



ğŸ’¾ Results Summary

Example outputs:

Model	                Accuracy	    F1-Score
ResNet-18	           68.9 %	        60.5 %
EfficientNet-B0	     67.6 %	        66.2 %
ConvNeXt-Tiny	        67.6 %	        66.2 %
ViT-B/16	              67.6 %	        66.2 %
Hybrid-Fusion (Ours)	  70.4 %	        69.1 %



ğŸ§© Key Components
Component	                                            Description
HybridFusionModel	                        Cross-modal Transformer fusion (ViT + AST)
train_all_models.py	                     Orchestrates full training & evaluation pipeline
compare_all_models.py	                  Generates final performance comparison graph
extract_pretrained_embeddings.py	         Extracts modality-specific embeddings
evaluate_model.py	                        Unified inference & metrics generation script
